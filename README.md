---
title: NCSU Research Assistant
emoji: ğŸº
colorFrom: red
colorTo: red
sdk: streamlit
sdk_version: "1.28.0"
python_version: "3.11"
app_file: app.py
pinned: false
---

# ğŸº NCSU Research Assistant

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A clean, deployable version of the NCSU Research Assistant web interface - an AI-powered research tool for NC State University that searches the university website, extracts content, and generates comprehensive answers with citations.

## ğŸ“ File Structure

```
Chatbot_Deploy/
â”œâ”€â”€ user_interface.py              # Main Streamlit web interface
â”œâ”€â”€ ncsu_advanced_config_base.py  # Core research engine
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ run_web_interface.bat         # Windows batch launcher
â”œâ”€â”€ run_web_interface.ps1         # PowerShell launcher
â”œâ”€â”€ NC_State_Wolfpack_logo.svg.png # Logo (left header)
â”œâ”€â”€ NC-State-University-Logo.png   # Logo (right header)
â”œâ”€â”€ src/                           # Source modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ncsu_scraper.py       # Website scraper
â”‚   â”‚   â”œâ”€â”€ content_aggregator.py # Content processor
â”‚   â”‚   â””â”€â”€ models.py             # Data models
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py              # Logging utility
â””â”€â”€ results/                       # Output directory
    â””â”€â”€ .gitkeep
```

## ğŸŒŸ Features

- **ğŸ” Intelligent Search**: Searches NCSU website using domain-specific search
- **ğŸ“„ Full Content Extraction**: Extracts 100% content from web pages using MarkItDown
- **ğŸ¤– LLM-Based Grading**: Uses AI to score content relevance (0-1 scale)
- **ğŸ“Š Smart Filtering**: Filters content by relevance threshold
- **ğŸ”— Rich Citations**: Generates answers with clickable source links
- **ğŸ¨ Beautiful UI**: NC State branded interface with Wolfpack logos
- **âš™ï¸ Configurable**: Adjustable search depth, relevance threshold, and LLM settings

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Chrome browser (for Selenium web scraping)
- **Optional**: OpenAI API key, Anthropic API key, or Hugging Face token
  - **Note**: Hugging Face models are **free** and work without any API key!

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/ncsu-research-assistant.git
cd ncsu-research-assistant
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Set Up API Key (Optional)

**Option A: Use Hugging Face (Free, Recommended)**
- No API key required! Just select "huggingface" as the provider in the interface.
- Optional: Add `HF_TOKEN` for higher rate limits (get from https://huggingface.co/settings/tokens)

**Option B: Use OpenAI or Anthropic**
Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your-api-key-here
# OR
ANTHROPIC_API_KEY=your-api-key-here
```

Or set it as an environment variable:

```bash
# Windows
set OPENAI_API_KEY=your-api-key-here

# Linux/Mac
export OPENAI_API_KEY=your-api-key-here
```

**Note**: Never commit your `.env` file to Git! It's already in `.gitignore`.

### 3. Launch the Web Interface

**Windows (Batch):**
```cmd
run_web_interface.bat
```

**Windows (PowerShell):**
```powershell
.\run_web_interface.ps1
```

**Manual:**
```bash
streamlit run user_interface.py
```

### 4. Access the Interface

Open your browser and go to:
```
http://localhost:8501
```

## ğŸ“‹ Requirements

- Python 3.8+
- Chrome browser (for Selenium)
- ChromeDriver (automatically managed by Selenium)

## ğŸ”§ Configuration

All settings can be adjusted in the web interface sidebar:
- LLM Provider (OpenAI/Anthropic/Mock)
- Model selection
- Search parameters
- Relevance threshold

## ğŸ“Š Output

All research results are automatically saved to the `results/` directory:
- `answer_[query]_[timestamp].txt` - Human-readable answer
- `data_[query]_[timestamp].json` - Complete research data
- `config_[query]_[timestamp].yaml` - Configuration used

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- NC State University for providing the website content
- OpenAI and Anthropic for LLM APIs
- Streamlit for the web framework
- All contributors and users

## ğŸº Go Pack!

Built with â¤ï¸ for NC State University

**Think and Do!**
